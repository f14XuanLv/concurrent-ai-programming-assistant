
# 并发 AI 编程助手

## 背景

大型语言模型（LLM），如 Gemini 和 Claude，越来越多地被用于协助开发人员修改代码。然而，一个常见的瓶颈是这些模型通常按顺序处理对单个文件或一组文件的修改请求。即使单个提示请求更改多个文件，开发人员也常常需要等待 AI 完成所有修改后才能看到结果。这可能导致大量的等待时间和效率降低。

**并发 AI 编程助手**是一个基于 Web 的 IDE，旨在应对这一挑战。它采用两级 AI 策略：

1.  **一级 AI（全局分析 - 手动步骤）：** 用户使用一个强大的人工智能（例如 Claude-4-opus 或功能强大的 Gemini 模型）对代码库进行全局分析。用户向 AI 提供项目结构、相关文件内容及其高级需求。AI 的作用是识别跨多个文件所有必要的修改，并以特定的结构化格式输出这些指令，包括建议的并发操作数。
2.  **二级 AI（文件特定执行 - 由本应用自动执行）：** 用户将一级 AI 的结构化输出粘贴到此应用程序中。然后，应用程序解析这些指令，并对指定的 Gemini 模型（默认为 `gemini-2.5-flash-preview-05-20`，用户可配置）进行并发 API 调用，以并行执行每个文件的特定代码修改。

这种方法旨在通过并行化单个文件修改的执行，显著加快将 AI 建议的更改应用于代码库的过程。

## 功能特性

*   **项目上传：** 直接在浏览器中上传整个项目文件夹。
*   **交互式文件树：** 查看和导航项目的目录结构。
*   **文件内容查看器：**
    *   显示基于文本的文件内容。
    *   直接在编辑器面板中渲染常见的图像类型（PNG、JPEG、GIF、SVG）。
*   **一级 AI 提示助手：**
    *   协助为用户选择的一级 AI 生成结构化提示。
    *   自动包含项目的文件树和上传文件列表。
    *   提供一个模板，供用户添加其特定的修改需求。
*   **一级 AI 输出处理：**
    *   解析来自一级 AI 的结构化输出（包含线程数和每个文件的详细修改指令）。
*   **并发二级 AI 执行：**
    *   根据解析的指令和建议的线程数，对配置的 Gemini 模型进行并行 API 调用。
*   **内存中文件更新：** 将从二级 AI 收到的修改应用于浏览器内的文件表示。
*   **可配置设置：**
    *   **API 密钥：** 用于向 Gemini API 进行身份验证。
    *   **API URL：** 可自定义的端点，通常是 Gemini API 的代理。
    *   **Gemini 模型名称：** 指定用于二级 AI 修改的 Gemini 模型（默认为 `gemini-2.5-flash-preview-05-20`）。
    *   **忽略的文件夹：** 指定文件夹（例如 `.git`、`node_modules`、`dist`）以：
        *   从一级 AI 提示内容中排除。
        *   在文件树中默认显示为折叠状态。
        *   在二级 AI 修改处理期间跳过。
*   **实时状态栏：** 提供有关当前操作、进度和错误的反馈。
*   **路径自动修正：** 如果一级 AI 输出的文件路径不包含根项目文件夹名称，则尝试修正它们。

## 工作流程

1.  **设置 API 配置（设置面板）：**
    *   输入您的 **Gemini API 密钥**。
    *   输入 **Gemini API URL** （通常是代理 URL，例如 `https://api-proxy.me/gemini`）。
    *   可选地，如果您想使用与默认模型（`gemini-2.5-flash-preview-05-20`）不同的模型，请设置 **Gemini 模型名称**。
    *   可选地，自定义**忽略的文件夹**列表（逗号分隔，例如 `.git,node_modules`）。
2.  **上传项目：**
    *   点击“上传项目文件夹”按钮。
    *   选择您要修改的项目的根文件夹。应用程序将读取文件并构建文件树。
3.  **准备一级 AI 提示（一级面板 - 步骤 1）：**
    *   在“您的需求”文本区域中，描述您希望 AI 进行的高级更改（例如，“将所有 API 调用函数重构为使用 async/await”，“将主色调更改为深蓝色”）。
    *   点击“准备/刷新一级提示模板”按钮。
    *   下方的大的文本区域将填充结构化的提示。此提示包括项目结构、相关文件列表、您的需求以及关于一级 AI 预期输出格式的详细说明。
    *   查看此生成的提示。如果需要，您可以进一步编辑它。
4.  **使用外部一级 AI（手动步骤）：**
    *   点击“复制一级提示”按钮。
    *   将此复制的提示粘贴到您选择的强大 LLM 中（例如 Claude 或功能强大的 Gemini 界面）。
    *   从此 AI 获取结构化响应。**至关重要的是，AI 必须严格遵守提示中指定的输出格式。**
5.  **处理一级 AI 输出（一级面板 - 步骤 2）：**
    *   将从一级 AI 收到的完整结构化输出粘贴到“在此处粘贴一级 AI 输出”文本区域中。
    *   点击“执行修改（调用二级 AI）”按钮。
6.  **并发执行和文件更新：**
    *   应用程序将：
        *   解析一级 AI 的输出。
        *   识别建议的并发线程数。
        *   对于每个文件修改指令：
            *   为二级 Gemini API 构建特定的提示（使用配置的模型名称）。
            *   并发调用所有文件的 Gemini API。
        *   从 Gemini 接收修改后的代码。
        *   将相应的更改更新到其内存中的项目表示。
7.  **审查更改：**
    *   文件树和编辑器面板将反映修改后的文件。
    *   如果文件被修改或删除，并且当前在编辑器面板中选中，其内容将更新。
    *   **注意：** 目前，所有更改都在内存中。此工具不会自动将更改保存回本地文件系统。

## 技术细节

*   **前端：** React (v19) 与 TypeScript，使用 Tailwind CSS 进行样式设计。
*   **AI 集成：**
    *   **一级（分析）：** 用户管理。应用程序帮助生成提示，但用户与他们选择的 LLM 外部交互。
    *   **二级（修改）：** Google Gemini API。具体模型由用户配置（默认为 `gemini-2.5-flash-preview-05-20`）。通过 `fetch` 对用户配置的（代理）URL 进行调用。
*   **核心逻辑：**
    *   内存中的文件系统表示。
    *   解析来自两级 AI 的结构化文本输出。
    *   使用 `Promise.all` 和批处理进行并发 API 请求管理，以控制并发性。
*   **打包/服务：** 直接在 `index.html` 中通过导入映射表（import map）导入 ES 模块，适用于现代浏览器和简单的本地服务器设置。

## 关键文件和结构

*   `index.html`: 主要的 HTML 入口点，包含 Tailwind CSS CDN 和导入映射表。
*   `index.tsx`: React 应用程序根初始化。
*   `App.tsx`: 主要的应用程序组件，处理状态管理、核心工作流逻辑以及不同面板之间的交互。
*   **`components/`**: 包含所有 React UI 组件：
    *   `SettingsPanel.tsx`: 用于 API 密钥、URL、Gemini 模型名称和忽略文件夹的配置。
    *   `FileTreePanel.tsx`: 显示项目的文件和文件夹结构。
    *   `EditorPanel.tsx`: 显示所选文件的内容（文本或图像）。
    *   `Level1Panel.tsx`: 管理两步 AI 交互工作流。
    *   `StatusBar.tsx`: 显示当前应用程序状态和消息。
    *   `Button.tsx`: 通用按钮组件。
*   **`services/`**:
    *   `fileParserService.ts`: 用于解析来自一级 AI 和二级 AI 的结构化文本输出的逻辑。
    *   `geminiService.ts`: 处理为二级 Gemini API 构建提示和调用该 API。
*   `types.ts`:整个应用程序中使用的 TypeScript 类型定义。
*   `constants.tsx`: 应用程序范围的常量，包括 API 默认值（如默认 Gemini 模型名称）、提示模板和 SVG 图标。

## 如何运行

1.  **先决条件：** 支持 ES 模块和 `fetch` 的现代 Web 浏览器。
2.  **提供文件服务：**
    *   由于应用程序使用 ES 模块，您需要通过本地 HTTP 服务器提供文件服务。
    *   您可以使用简单的工具，例如：
        *   `npx serve .` （如果您安装了 Node.js/npm）
        *   Python 的 `python -m http.server` （对于 Python 3）
        *   VS Code 的 "Live Server" 扩展。
    *   从 `index.html` 所在的根目录提供服务。
3.  **访问应用程序：** 打开您的 Web 浏览器并导航到本地 HTTP 服务器提供的地址（例如 `http://localhost:3000` 或 `http://localhost:8000`）。
4.  **API 配置：**
    *   加载后，转到**设置面板**。
    *   输入有效的 **Gemini API 密钥**。默认密钥是占位符，无法工作。
    *   **Gemini API URL** 默认为 `https://api-proxy.me/gemini`。如果您使用不同的代理或 Gemini API 端点结构发生更改，则可能需要调整此设置。浏览器直接调用 Gemini API 通常会被 CORS 阻止，因此需要代理。
    *   **Gemini 模型名称** 默认为 `gemini-2.5-flash-preview-05-20`。如果您希望为二级 AI 修改使用不同的模型，可以更改此设置。

## 重要注意事项

*   **API 密钥安全：** API 密钥由用户输入并存储在浏览器的组件状态中。对于本地开发和个人使用，这很方便。在任何更广泛或共享的部署中，应更加谨慎地处理 API 密钥（例如，由服务器端代理注入密钥）。
*   **一级 AI 输出格式：** 该工具正确处理修改的能力**高度依赖于**一级 AI 严格遵守指定的输出格式。任何偏差都可能导致解析错误。
*   **Gemini API 代理：** 该应用程序设计为与 Gemini API 的代理一起工作，以避免 CORS 问题。确保您的代理配置正确且可访问。
*   **内存操作：** 所有文件上传和修改当前都在浏览器会话的内存中处理。刷新页面将清除状态。没有内置功能可将修改后的文件保存回本地磁盘。
*   **错误处理：** 实现了基本的错误处理，消息显示在状态栏中，更详细的错误记录到浏览器控制台。
*   **实验性质：** 这是一个演示概念的原型。虽然在其描述的工作流程中功能正常，但它可能存在限制或错误。

## 未来增强（潜在想法）

*   直接“保存到磁盘”或“下载项目”功能。
*   与 Git 集成以进行版本控制。
*   更复杂的 API 调用错误恢复和重试机制。
*   支持其他二级 AI 模型。
*   在应用更改前可视化差异的 UI。
*   来自二级 AI 的流式响应以获得更快的反馈。
*   用户可配置的二级提示模板。
