# 并发 AI 编程助手

## 背景

大型语言模型（LLM），如 Gemini 和 Claude，越来越多地被用于协助开发人员修改代码。然而，一个常见的瓶颈是这些模型通常按顺序处理对单个文件或一组文件的修改请求。

**并发 AI 编程助手**是一个基于 Web 的 IDE，旨在应对这一挑战。它采用两级 AI 策略：

1.  **一级 AI（全局分析 - 手动步骤）：** 用户使用一个强大的人工智能（例如 Claude-4-opus 或功能强大的 Gemini 模型）对代码库进行全局分析。用户向 AI 提供项目结构、相关文件内容及其高级需求。AI 的作用是识别跨多个文件所有必要的修改，并以特定的结构化格式输出这些指令。
2.  **二级 AI（文件特定执行 - 由本应用自动执行）：** 用户将一级 AI 的结构化输出粘贴到此应用程序中。应用程序然后解析这些指令，并根据以下模式触发二级 AI 调用：
    *   **模式 1：使用部署者的凭据（通过后端代理 - 默认）**
        *   **条件：** 应用设置面板中的“您的 Gemini API 密钥”字段保持*空白*。
        *   **操作：** 客户端应用将修改详情（提示、模型名称）发送到**后端代理函数**（例如，托管在 Vercel 上的 `/api/gemini`）。
        *   **代理行为：** 此代理安全地使用部署者设置的服务器端环境变量 `GEMINI_API_KEY`（以及可选的 `GEMINI_API_URL`）来对配置的 Gemini 模型进行实际调用。
    *   **模式 2：使用用户的凭据（直接客户端调用）**
        *   **条件：** 用户在应用设置面板中*输入自己的 Gemini API 密钥*。
        *   **操作：** 应用程序使用用户提供的 API 密钥和配置的模型**直接从浏览器**对 Gemini API 进行调用。用户还可以在设置中选择指定一个 API URL。

这种方法旨在通过并行化单个文件修改的执行，显著加快将 AI 建议的更改应用于代码库的过程，同时在 API 密钥管理方面提供灵活性和安全性。

## 功能特性

*   **项目上传：** 直接在浏览器中上传整个项目文件夹。
*   **交互式文件树和查看器：** 导航项目结构，查看文本文件，渲染图像。
*   **一级 AI 提示助手：** 协助为用户选择的一级 AI 生成结构化提示。
*   **一级 AI 输出处理：** 解析来自一级 AI 的结构化输出。
*   **双模式二级 AI 执行：**
    *   **后端代理（默认）：** 客户端将修改详情发送到 `/api/gemini`。代理使用部署者配置的 `GEMINI_API_KEY` 和可选的 `GEMINI_API_URL`。
    *   **客户端直接调用（可选）：** 如果用户在设置中提供了自己的 API 密钥和可选的 API URL，则直接从浏览器进行调用。
    *   根据一级 AI 建议的线程数并行执行。
*   **内存中文件更新：** 将从二级 AI 收到的修改应用于浏览器内的文件表示。
*   **可配置设置：**
    *   **您的 Gemini API 密钥（二级 AI）：** 可选。如果提供，二级 AI 调用将在客户端进行。
    *   **您的 Gemini API URL（二级 AI）：** 可选。与您的 API 密钥一起用于客户端调用。默认为 `https://generativelanguage.googleapis.com`。
    *   **Gemini 模型名称（二级 AI）：** 指定用于二级 AI 调用的模型（两种模式均使用）。
    *   **忽略的文件夹：** 从一级提示中排除、在树中折叠显示并在二级修改中跳过的文件夹。
*   **实时状态栏：** 提供有关当前操作、进度和错误的反馈。
*   **路径自动修正：** 尝试修正一级 AI 输出中的文件路径。

## 工作流程

1.  **设置 AI 配置（设置面板）：**
    *   要使用 **模式 1 (后端代理 - 默认)**：将“您的 Gemini API 密钥”留空。应用将使用部署者配置的代理。
    *   要使用 **模式 2 (客户端直接调用)**：提供“您的 Gemini API 密钥”以及可选的“您的 Gemini API URL”。
    *   设置 **Gemini 模型名称**（用于二级 AI 调用）。
    *   可选地，自定义**忽略的文件夹**列表。
2.  **上传项目：** 点击“上传项目文件夹”按钮。
3.  **准备一级 AI 提示（一级面板 - 步骤 1）：**
    *   在“您的需求”文本区域中描述您的高级需求。
    *   点击“准备/刷新一级提示模板”按钮。
    *   查看并编辑生成的提示。
4.  **使用外部一级 AI（手动步骤）：**
    *   复制一级提示。
    *   将其粘贴到您选择的强大 LLM 中，并获取结构化响应。
5.  **处理一级 AI 输出（一级面板 - 步骤 2）：**
    *   粘贴 AI 的输出。
    *   点击“执行修改”。这将触发二级 AI 调用。
6.  **并发执行和文件更新：** 文件在内存中更新。
7.  **审查更改。**

## 技术细节

*   **前端：** React (v19) 与 TypeScript，使用 Tailwind CSS 进行样式设计。
*   **后端代理（用于二级 AI - 默认模式）：** Vercel 无服务器函数 (例如 `api/gemini.ts`)。
    *   安全地处理部署者的 `GEMINI_API_KEY` 以及可选的 `GEMINI_API_URL`。
    *   使用 `@google/genai` SDK 调用 Gemini API。
*   **AI 集成：**
    *   **一级（分析）：** 用户管理。
    *   **二级（修改）：**
        *   如果用户提供了 API 密钥，则直接从客户端调用。
        *   如果未提供用户 API 密钥，则通过后端代理（默认）。
*   **环境变量（针对 Vercel 上的部署者 - 用于后端代理模式）：**
    *   `GEMINI_API_KEY`: (后端代理二级 AI 必需) 您的 Google Gemini API 密钥。
    *   `GEMINI_API_URL`: (后端代理二级 AI 可选) 用于 Gemini 的自定义 API 端点。如果未设置，则默认为 Google 的生产端点。
    *   这些变量在 Vercel 项目设置为无服务器函数设置，**不带 `VITE_` 前缀**。后端代理 (`api/gemini.ts`) 通过 `process.env` 读取。
*   **打包/服务：** 客户端使用 ES 模块/Vite。无服务器函数由 Vercel 处理。

## 如何运行 (本地开发)

**使用 Vite 和 Vercel CLI (推荐以获得完整功能, 包括后端代理)**
1.  安装 Node.js。
2.  安装 Vercel CLI: `npm install -g vercel`。
3.  运行 `npm install` (如果存在包含如 `react`, `tailwindcss` 等依赖的 `package.json` 文件，或手动安装它们)。
4.  **本地环境变量 (用于后端代理):**
    *   在项目根目录中创建一个 `.env.local` 文件 (此文件通常被 gitignore)。
    *   要测试后端代理模式，请添加部署者的 Gemini API 密钥和可选的 URL:
        *   `GEMINI_API_KEY=your_actual_gemini_api_key_for_proxy`
        *   `GEMINI_API_URL=your_optional_custom_api_url_for_proxy` (如果未设置，则默认为 Google 的端点)
    *   Vercel CLI (`vercel dev`) 将为本地无服务器函数环境加载这些变量。
5.  在项目目录中运行 `vercel dev`。这将为前端提供服务，并在本地运行 `api/gemini.ts` 函数。
6.  访问 `vercel dev` 提供的 URL (例如, `http://localhost:3000`)。
7.  在应用的设置面板中，您可以将“您的 Gemini API 密钥”留空以测试代理，或填写它以测试直接的客户端调用。

**更简单的前端服务 (后端代理将无法工作)**
1.  使用 Vite 提供前端文件服务: `npm install -g vite` 然后 `vite`。
2.  如果您未在设置中提供“您的 Gemini API 密钥”，二级 AI 调用将会失败，因为它们会尝试访问 `/api/gemini`，而该代理在此模式下未运行。您必须提供自己的密钥以进行客户端调用。

## 部署

### Vercel (推荐以获得后端代理功能)

1.  **推送到 Git。**
2.  **导入到 Vercel。**
    *   **Framework Preset (框架预设):** 选择 "Vite" (或 "Other" 并配置构建命令 `vite build`)。
    *   **Output Directory (输出目录):** Vercel 通常能正确检测到 Vite 的输出目录 (`dist`)。
    *   Vercel 将自动检测并部署 `api` 目录中的无服务器函数。
3.  **在 Vercel 上配置环境变量 (用于后端代理):**
    *   在您的 Vercel 项目仪表板中，转到 "Settings" -> "Environment Variables"。
    *   为代理添加您的**服务器端** Gemini API 密钥和可选的 URL:
        *   名称: `GEMINI_API_KEY`, 值: Your_Actual_Google_Gemini_API_Key_For_Proxy_Mode
        *   名称: `GEMINI_API_URL`, 值: Your_Optional_Custom_API_URL_For_Proxy (如果未设置, 则使用 Google 的默认端点)
    *   **不要使用 `VITE_` 前缀**，因为这些密钥用于后端代理。
4.  **部署。**
5.  您部署的应用的最终用户可以选择通过设置面板使用他们自己的 API 密钥进行客户端调用。

## 重要注意事项

*   **API 密钥安全：**
    *   **后端代理模式：** 部署者的 `GEMINI_API_KEY`（和 `GEMINI_API_URL`）作为服务器端环境变量安全地存储在 Vercel 上。
    *   **客户端模式：** 如果用户在设置中输入其 API 密钥，该密钥将在其浏览器中使用，并受该用户会话的客户端暴露风险影响。如果用户使用自己的密钥，应意识到这一点。
*   **一级 AI 输出格式：** 严格遵守指定的输出格式至关重要。
*   **内存操作：** 刷新页面将清除上传的文件和更改。
*   **代理函数：** `/api/gemini` 函数对于默认的二级 AI 模式至关重要。

## 未来增强（潜在想法）

*   保存/下载项目功能。
*   Git 集成。
*   差异可视化。
*   如果应用公开，为代理端点添加身份验证/授权。